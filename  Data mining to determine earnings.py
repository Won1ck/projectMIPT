# -*- coding: utf-8 -*-
"""Москалев_Кирилл_2_вариант.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1btXoH_35bOPXe5TqmWD-QcaWab2SgOJL

# Задача
В этой работе вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:
 - age
 - workclass
 - fnlwgt
 - education
 - education-num
 - marital-status
 - occupation
 - relationship
 - race
 - sex
 - capital-gain
 - capital-loss
 - hours-per-week

Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*.

В этой задаче для обучения будут использовать 2 алгоритма:
 - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)
 - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)

# Решение

```
# Выбран кодовый формат
```

Загрузите набор данных *data.adult.csv* с помощью `pandas` (скачать можно [здесь](https://drive.google.com/file/d/1Lo47fXx1RrJG3v9E-Gck1T45n5bJ_SJf/view?usp=sharing), или с помощью скрипта ниже). Чтобы лучше понимать, с чем вы работаете/корректно ли вы загрузили данные можно вывести несколько первых строк на экран.
"""

!gdown 1Lo47fXx1RrJG3v9E-Gck1T45n5bJ_SJf

import pandas as pd
data = pd.read_csv("data.adult.csv")
print(data.head())

"""## Анализ и предобработка данных

Обычно после загрузки датасета всегда необходима его некоторая предобработка. В данном случае она будет заключаться в следующем:
1. Проверьте есть ли в данных пропущенные значения (здесь они обозначены как "?"). Удалите из выборки все объекты с пропусками.
2. Выделите 60% выборки для обучения и дальнейшего анализа.
3. Обратите внимание, что не все признаки являются вещественными (числовыми). Сначала их необходимо проанализировать и по необходимости предобработать. Все шаги предобработки поясните текстом.
4. Целевую переменную (ту, которую мы хотим предсказывать) можно выделить в отдельную переменную и преобразуйте к бинарному формату (НЕ забудьте удалить ее из датасета, когда будете обучать модель).

# Проверка наличия пропущенных значений и удаление объектов с пропусками
"""

data = data.replace('?', pd.NA).dropna()

"""# Выделение 60% выборки для обучения

"""

train_size = int(0.6 * len(data))
train_data = data[:train_size]

"""# Анализ и предобработка признаков (необходимо выполнить кодирование категориальных признаков)

"""

categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']

train_data_encoded = pd.get_dummies(train_data, columns=categorical_features)

"""# Выделение целевой переменной и преобразование к бинарному формату

"""

target = train_data['>50K,<=50K'].map({'<=50K': 0, '>50K': 1})
train_data.drop(columns=['>50K,<=50K'], inplace=True)

"""При обучении алгоритмов стоит обращать внимание не только на их качество, но и каким образом они работают с данными. Давайте посмотрим на значения самих признаков.

Что можете сказать о разбросе данных и сбалансированности выборки? В каком диапазоне лежат исследуемые признаки?
"""

numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']

"""## Добавление категориальных признаков

Добавим к предобработанным вещественным признакам категориальные. Но для начала их тоже необходимо предобработать.

Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) из sklearn).

После преобразования категориальных признаков, добавьте их к вещественным предобработанным данным для обучения.

>PS Напоминаю, что важно удалить колонку с целевым значением
"""

categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']
train_data_categorical = pd.get_dummies(train_data[categorical_features])
train_data_processed = pd.concat([train_data.drop(columns=categorical_features), train_data_categorical], axis=1)

"""## Обучение классификаторов

В начале посмотрим, как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 2 алгоритма:
 - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)
 - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)

Для начала обучим  выберем один гиперпараметр, который будем оптимизировать, — глубина дерева (*max_depth*).

Остальные параметры оставляйте в значениях по умолчанию.

Для каждого алгоритма подберите оптимальные значения указанных гиперпараметров. Постройте график среднего значения качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразите доверительный интервал.

Что вы можете сказать о получившихся графиках? Какой алгоритм справился лучше? Какой быстрее? Почему?
"""

from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

"""# Определение гиперпараметров для подбора

"""

param_grid = {'max_depth': range(1, 21)}  # Пробуем значения от 1 до 20

"""# Обучение DecisionTreeClassifier с использованием кросс-валидации для подбора оптимального значения глубины дерева

"""

dt_classifier = DecisionTreeClassifier(random_state=42)
dt_grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='accuracy')
dt_grid_search.fit(train_data_processed, target)

"""# Обучение RandomForestClassifier с использованием кросс-валидации для подбора оптимального значения глубины дерева

"""

rf_classifier = RandomForestClassifier(random_state=42)
rf_grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')
rf_grid_search.fit(train_data_processed, target)

"""# Построение графиков среднего значения качества по кросс-валидации для каждого значения гиперпараметра

"""

plt.figure(figsize=(10, 6))
plt.plot(param_grid['max_depth'], dt_grid_search.cv_results_['mean_test_score'], label='DecisionTree', marker='o')
plt.plot(param_grid['max_depth'], rf_grid_search.cv_results_['mean_test_score'], label='RandomForest', marker='o')
plt.xlabel('Max Depth')
plt.ylabel('Mean CV Accuracy')
plt.title('Mean CV Accuracy vs Max Depth')
plt.legend()
plt.grid(True)
plt.show()

"""Далее произведем подбор других гиперпараметров алгоритмов. Начнет со случайного леса. Для начала подберём число деревьев (*n_estimators*) в алгоритме RandomForest. Как известно, в общем случае Random Forest не переобучается с увеличением количества деревьев. Подберите количество деревьев, начиная с которого качество на кросс-валидации стабилизируется. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев. Обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества деревьев разных размеров, состоящих из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте подобранное количество деревьев.

# Обучение RandomForestClassifier с максимальным интересным количеством деревьев
"""

max_estimators = 100
rf_classifier_max_estimators = RandomForestClassifier(n_estimators=max_estimators, random_state=42)
rf_classifier_max_estimators.fit(train_data_processed, target)

"""# Подбор оптимального числа деревьев на основе стабилизации качества на кросс-валидации

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
mean_cv_scores = []
for i in range(1, max_estimators + 1):
    rf_classifier_subset = RandomForestClassifier(n_estimators=i, random_state=42)
    rf_classifier_subset.estimators_ = rf_classifier_max_estimators.estimators_[:i]
    # Используем подмножество деревьев
    cv_scores = cross_val_score(rf_classifier_subset, train_data_processed, target, cv=5, scoring='accuracy')
    mean_cv_scores.append(cv_scores.mean())

"""# Находим количество деревьев, начиная с которого качество на кросс-валидации стабилизируется

"""

stable_estimators = next(i for i, score in enumerate(mean_cv_scores, 1) if score == mean_cv_scores[-1])

print(f"Оптимальное количество деревьев: {stable_estimators}")

"""Теперь подберите следующие оптимальные параметры:
- максимальная глубина решающего дерева (*max_depth*)
- функция оценки качества разбиения (*criterion*)
- максимальное количесво учитываемых признаков при разбиении (*max_features*)

Остальные параметры оставляйте по умолчанию, за исключением парамтра `n_estimators` для случайного леса, выбранного на предыдущем шаге.

Оцените скорость обучения каждого из алгоритмов. Для этого воспользуйтесь графиком вида "ящик с усами", который отражает среднее время обучения алгоритма при фиксированном значении гиперпараметров. Что вы можете сказать о скорости работы алгоритмов? Почему наблюдаются такие результаты? Можно ли ускорить? Если да, то каким образом?

# Определение гиперпараметров для подбора
"""

from sklearn.model_selection import cross_val_score
import numpy as np
param_grid_dt = {
    'max_depth': range(1, 21),
    'criterion': ['gini', 'entropy'],
    'max_features': ['sqrt', 'log2', None]
}

"""# Подбор оптимальных значений гиперпараметров для DecisionTreeClassifier

"""

dt_classifier = DecisionTreeClassifier(random_state=42)
dt_grid_search = GridSearchCV(dt_classifier, param_grid_dt, cv=5, scoring='accuracy')
dt_grid_search.fit(train_data_processed, target)

"""# Вывод наилучших значений гиперпараметров и соответствующего качества

"""

print("DecisionTreeClassifier:")
print("Best Parameters:", dt_grid_search.best_params_)
print("Best CV Score:", dt_grid_search.best_score_)

"""# Измерение времени обучения DecisionTreeClassifier

"""

import time

def measure_training_time(classifier, train_data, target):
    start_time = time.time()
    classifier.fit(train_data, target)
    end_time = time.time()
    training_time = end_time - start_time
    return training_time
dt_classifier_best = DecisionTreeClassifier(**dt_grid_search.best_params_, random_state=42)
dt_training_times = []
for i in range(10):
    dt_training_time = measure_training_time(dt_classifier_best, train_data_processed, target)
    dt_training_times.append(dt_training_time)
    print(f"Iteration {i+1}: Training time = {dt_training_time:.4f} seconds")
print("Mean Training Time:", np.mean(dt_training_times))
print("Training Time Std:", np.std(dt_training_times))

"""## Сравнение результатов

Сравните результаты алгоритмво. Для этого воспользуйтесь "ящиком с усами" (boxplot).

Сделайте общие итоговые выводы о классификаторах с точки зрения их работы с признаками и сложности самой модели (какие гиперпараметры есть у модели, сильно ли изменение значения гиперпараметра влияет на качество модели).

# Обучение RandomForestClassifier с оптимальным числом деревьев
"""

import seaborn as sns
rf_classifier_optimal = RandomForestClassifier(n_estimators=stable_estimators, random_state=42)
rf_training_times = []
for i in range(10):
    rf_training_time = measure_training_time(rf_classifier_optimal, train_data_processed, target)
    rf_training_times.append(rf_training_time)
    print(f"Iteration {i+1}: Training time = {rf_training_time:.4f} seconds")

"""# Вывод среднего времени обучения и доверительного интервала для RandomForestClassifier

"""

print("RandomForestClassifier:")
print("Mean Training Time:", np.mean(rf_training_times))
print("Training Time Std:", np.std(rf_training_times))

"""# Сравнение времени обучения обеих моделей с помощью ящика с усами

"""

plt.figure(figsize=(8, 6))
sns.boxplot(data=[dt_training_times, rf_training_times], palette="Set3")
plt.xticks([0, 1], ['DecisionTree', 'RandomForest'])
plt.ylabel('Training Time (seconds)')
plt.title('Comparison of Training Time between DecisionTree and RandomForest')
plt.grid(True)
plt.show()

"""## Тестирование всех модели

Протестируйте последние построенные модели (наилучшее решающее дерево и наилучший случайный лес) на данных, которые были отложены для теста (их должно было остаться 40%). Не забудьте про все необходимые преобразования.

# Загрузка тестовых данных
"""

import pandas as pd

# Загрузка данных
data1 = pd.read_csv('/content/data.adult.csv')
data2 = pd.read_csv('/content/test_data.csv')

# Вывод первых нескольких строк для ознакомления
print("Data1 (data.adult-3.csv) head:")
print(data1.head())

print("\nData2 (test_data-2.csv) head:")
print(data2.head())

# Проверка на пропущенные значения
print("\nMissing values in Data1:")
print(data1.isnull().sum())

print("\nMissing values in Data2:")
print(data2.isnull().sum())

"""Предварительный анализ данных
Данные из data.adult-3.csv:

Структура таблицы включает такие столбцы, как возраст (age), рабочий класс (workclass), вес по окончании (fnlwgt), образование (education), количество лет обучения (education-num), семейное положение (marital-status), профессия (occupation), отношения в семье (relationship), раса (race), пол (sex), прирост капитала (capital-gain), убыток капитала (capital-loss), количество рабочих часов в неделю (hours-per-week) и целевая переменная (заработок, закодированная как >50K,<=50K).
Данные из test_data-2.csv:

Структура таблицы аналогична первому файлу, однако целевая переменная уже закодирована в бинарный формат (0 и 1).
Шаги для дальнейшей обработки:
Преобразование целевой переменной в data.adult-3.csv к бинарному формату.
Преобразование категориальных переменных к числовому формату (используя метод кодирования One-Hot).
Разделение данных на обучающую и тестовую выборки.
Обучение моделей DecisionTreeClassifier и RandomForestClassifier.
Вывод результатов.
"""

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Преобразование целевой переменной в data1 к бинарному формату
data1['>50K,<=50K'] = data1['>50K,<=50K'].apply(lambda x: 1 if x == '>50K' else 0)

# Кодирование категориальных переменных в обоих датасетах
categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']

# Объединение датасетов для обеспечения одинакового кодирования
combined_data = pd.concat([data1, data2], keys=['data1', 'data2'])

# One-Hot Encoding
combined_data = pd.get_dummies(combined_data, columns=categorical_columns)

# Разделение обратно на два набора данных
data1 = combined_data.xs('data1')
data2 = combined_data.xs('data2')

# Проверка изменений
print("Data1 transformed head:")
print(data1.head())

print("\nData2 transformed head:")
print(data2.head())

# Подгрузка данных
data1 = pd.read_csv('/content/data.adult.csv')
data2 = pd.read_csv('/content/test_data.csv')

# Преобразование целевой переменной в data1 к бинарному формату
data1['>50K,<=50K'] = data1['>50K,<=50K'].apply(lambda x: 1 if x == '>50K' else 0)

# Проверка на пропущенные значения
print("Missing values in Data1:")
print(data1.isnull().sum())

print("Missing values in Data2:")
print(data2.isnull().sum())

# Заполнение пропущенных значений (если есть)
data1.fillna(0, inplace=True)
data2.fillna(0, inplace=True)

# Кодирование категориальных переменных в обоих датасетах
categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']

# Объединение датасетов для обеспечения одинакового кодирования
combined_data = pd.concat([data1, data2], keys=['data1', 'data2'])

# One-Hot Encoding
combined_data = pd.get_dummies(combined_data, columns=categorical_columns)

# Разделение обратно на два набора данных
data1 = combined_data.xs('data1')
data2 = combined_data.xs('data2')

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Разделение данных на признаки (X) и целевую переменную (y)
X1 = data1.drop(columns=['>50K,<=50K'])
y1 = data1['>50K,<=50K']

X2 = data2.drop(columns=['>50K,<=50K'])
y2 = data2['>50K,<=50K']

# Разделение на обучающую и тестовую выборки
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)

# Обучение моделей
dt_classifier = DecisionTreeClassifier(random_state=42)
rf_classifier = RandomForestClassifier(random_state=42)

dt_classifier.fit(X1_train, y1_train)
rf_classifier.fit(X2_train, y2_train)

# Оценка моделей
dt_predictions = dt_classifier.predict(X1_test)
rf_predictions = rf_classifier.predict(X2_test)

dt_test_score = accuracy_score(y1_test, dt_predictions)
rf_test_score = accuracy_score(y2_test, rf_predictions)

"""# Вывод результатов"""

# Вывод результатов
print("DecisionTreeClassifier Test Score:", dt_test_score)
print("RandomForestClassifier Test Score:", rf_test_score)
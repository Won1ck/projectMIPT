{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rX8cvHCzany"
      },
      "source": [
        "# Задача\n",
        "В этой работе вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
        " - age\n",
        " - workclass\n",
        " - fnlwgt\n",
        " - education\n",
        " - education-num\n",
        " - marital-status\n",
        " - occupation\n",
        " - relationship\n",
        " - race\n",
        " - sex\n",
        " - capital-gain\n",
        " - capital-loss\n",
        " - hours-per-week\n",
        "\n",
        "Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*.\n",
        "\n",
        "В этой задаче для обучения будут использовать 2 алгоритма:\n",
        " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
        " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKvOO2LGzan3"
      },
      "source": [
        "# Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrewBnQJibsR"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Выбран кодовый формат\n",
        "```\n",
        "\n",
        "Загрузите набор данных *data.adult.csv* с помощью `pandas` (скачать можно [здесь](https://drive.google.com/file/d/1Lo47fXx1RrJG3v9E-Gck1T45n5bJ_SJf/view?usp=sharing), или с помощью скрипта ниже). Чтобы лучше понимать, с чем вы работаете/корректно ли вы загрузили данные можно вывести несколько первых строк на экран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "So-LVYjsibsU"
      },
      "outputs": [],
      "source": [
        "!gdown 1Lo47fXx1RrJG3v9E-Gck1T45n5bJ_SJf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpDKy6jCzan6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"data.adult.csv\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTJwqn6Xzan6"
      },
      "source": [
        "## Анализ и предобработка данных\n",
        "\n",
        "Обычно после загрузки датасета всегда необходима его некоторая предобработка. В данном случае она будет заключаться в следующем:\n",
        "1. Проверьте есть ли в данных пропущенные значения (здесь они обозначены как \"?\"). Удалите из выборки все объекты с пропусками.\n",
        "2. Выделите 60% выборки для обучения и дальнейшего анализа.\n",
        "3. Обратите внимание, что не все признаки являются вещественными (числовыми). Сначала их необходимо проанализировать и по необходимости предобработать. Все шаги предобработки поясните текстом.\n",
        "4. Целевую переменную (ту, которую мы хотим предсказывать) можно выделить в отдельную переменную и преобразуйте к бинарному формату (НЕ забудьте удалить ее из датасета, когда будете обучать модель).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка наличия пропущенных значений и удаление объектов с пропусками\n"
      ],
      "metadata": {
        "id": "s0DgDnKoyYlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LCu1pI4zan6"
      },
      "outputs": [],
      "source": [
        "data = data.replace('?', pd.NA).dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выделение 60% выборки для обучения\n"
      ],
      "metadata": {
        "id": "mGtzy0cGycCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.6 * len(data))\n",
        "train_data = data[:train_size]\n"
      ],
      "metadata": {
        "id": "zj9-kIJ0yd61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ и предобработка признаков (необходимо выполнить кодирование категориальных признаков)\n"
      ],
      "metadata": {
        "id": "T8RaF39Sygad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
        "\n",
        "train_data_encoded = pd.get_dummies(train_data, columns=categorical_features)"
      ],
      "metadata": {
        "id": "I1rNHLSByf_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выделение целевой переменной и преобразование к бинарному формату\n"
      ],
      "metadata": {
        "id": "y_pgel8ayyie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = train_data['>50K,<=50K'].map({'<=50K': 0, '>50K': 1})\n",
        "train_data.drop(columns=['>50K,<=50K'], inplace=True)\n"
      ],
      "metadata": {
        "id": "fjDE1QR6yzKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A58Y5VpIzan_"
      },
      "source": [
        "При обучении алгоритмов стоит обращать внимание не только на их качество, но и каким образом они работают с данными. Давайте посмотрим на значения самих признаков.\n",
        "\n",
        "Что можете сказать о разбросе данных и сбалансированности выборки? В каком диапазоне лежат исследуемые признаки?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
      ],
      "metadata": {
        "id": "BIDIZhG_k6bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Добавление категориальных признаков\n",
        "\n",
        "Добавим к предобработанным вещественным признакам категориальные. Но для начала их тоже необходимо предобработать.\n",
        "\n",
        "Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) из sklearn).\n",
        "\n",
        "После преобразования категориальных признаков, добавьте их к вещественным предобработанным данным для обучения.\n",
        "\n",
        ">PS Напоминаю, что важно удалить колонку с целевым значением"
      ],
      "metadata": {
        "id": "NkRMwGjTydZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
        "train_data_categorical = pd.get_dummies(train_data[categorical_features])\n",
        "train_data_processed = pd.concat([train_data.drop(columns=categorical_features), train_data_categorical], axis=1)\n"
      ],
      "metadata": {
        "id": "gMRvsV-xaJ0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpAcHTeHzan7"
      },
      "source": [
        "## Обучение классификаторов\n",
        "\n",
        "В начале посмотрим, как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 2 алгоритма:\n",
        " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
        " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала обучим  выберем один гиперпараметр, который будем оптимизировать, — глубина дерева (*max_depth*).\n",
        "\n",
        "Остальные параметры оставляйте в значениях по умолчанию.\n",
        "\n",
        "Для каждого алгоритма подберите оптимальные значения указанных гиперпараметров. Постройте график среднего значения качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразите доверительный интервал.\n",
        "\n",
        "Что вы можете сказать о получившихся графиках? Какой алгоритм справился лучше? Какой быстрее? Почему?"
      ],
      "metadata": {
        "id": "tbD3Q4fpsKn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8DLchYEQzan-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Определение гиперпараметров для подбора\n"
      ],
      "metadata": {
        "id": "uCF5QVu1zgRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'max_depth': range(1, 21)}  # Пробуем значения от 1 до 20\n"
      ],
      "metadata": {
        "id": "eSd8i1GJzfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение DecisionTreeClassifier с использованием кросс-валидации для подбора оптимального значения глубины дерева\n"
      ],
      "metadata": {
        "id": "fE9sHco8zkEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "dt_grid_search.fit(train_data_processed, target)"
      ],
      "metadata": {
        "id": "JGwg5RuhzjNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение RandomForestClassifier с использованием кросс-валидации для подбора оптимального значения глубины дерева\n"
      ],
      "metadata": {
        "id": "FF1hEJCZznkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "rf_grid_search.fit(train_data_processed, target)"
      ],
      "metadata": {
        "id": "zWtQLSJCzpDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Построение графиков среднего значения качества по кросс-валидации для каждого значения гиперпараметра\n"
      ],
      "metadata": {
        "id": "GPNVLPIQzq8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(param_grid['max_depth'], dt_grid_search.cv_results_['mean_test_score'], label='DecisionTree', marker='o')\n",
        "plt.plot(param_grid['max_depth'], rf_grid_search.cv_results_['mean_test_score'], label='RandomForest', marker='o')\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Mean CV Accuracy')\n",
        "plt.title('Mean CV Accuracy vs Max Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xxaKO_Zrzs3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri4UoyZBzan8"
      },
      "source": [
        "Далее произведем подбор других гиперпараметров алгоритмов. Начнет со случайного леса. Для начала подберём число деревьев (*n_estimators*) в алгоритме RandomForest. Как известно, в общем случае Random Forest не переобучается с увеличением количества деревьев. Подберите количество деревьев, начиная с которого качество на кросс-валидации стабилизируется. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев. Обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества деревьев разных размеров, состоящих из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте подобранное количество деревьев."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение RandomForestClassifier с максимальным интересным количеством деревьев\n"
      ],
      "metadata": {
        "id": "gj8KMVBC0szh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_estimators = 100\n",
        "rf_classifier_max_estimators = RandomForestClassifier(n_estimators=max_estimators, random_state=42)\n",
        "rf_classifier_max_estimators.fit(train_data_processed, target)"
      ],
      "metadata": {
        "id": "jF8BDQtiHxi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подбор оптимального числа деревьев на основе стабилизации качества на кросс-валидации\n"
      ],
      "metadata": {
        "id": "XiS6pFnG0v5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "mean_cv_scores = []\n",
        "for i in range(1, max_estimators + 1):\n",
        "    rf_classifier_subset = RandomForestClassifier(n_estimators=i, random_state=42)\n",
        "    rf_classifier_subset.estimators_ = rf_classifier_max_estimators.estimators_[:i]\n",
        "    # Используем подмножество деревьев\n",
        "    cv_scores = cross_val_score(rf_classifier_subset, train_data_processed, target, cv=5, scoring='accuracy')\n",
        "    mean_cv_scores.append(cv_scores.mean())"
      ],
      "metadata": {
        "id": "x2OOGqG-0vlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Находим количество деревьев, начиная с которого качество на кросс-валидации стабилизируется\n"
      ],
      "metadata": {
        "id": "leSoL83o0zVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stable_estimators = next(i for i, score in enumerate(mean_cv_scores, 1) if score == mean_cv_scores[-1])\n"
      ],
      "metadata": {
        "id": "TwnXrMHR00t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Оптимальное количество деревьев: {stable_estimators}\")\n"
      ],
      "metadata": {
        "id": "21iq0mAC02Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь подберите следующие оптимальные параметры:\n",
        "- максимальная глубина решающего дерева (*max_depth*)\n",
        "- функция оценки качества разбиения (*criterion*)\n",
        "- максимальное количесво учитываемых признаков при разбиении (*max_features*)\n",
        "\n",
        "Остальные параметры оставляйте по умолчанию, за исключением парамтра `n_estimators` для случайного леса, выбранного на предыдущем шаге.\n",
        "\n",
        "Оцените скорость обучения каждого из алгоритмов. Для этого воспользуйтесь графиком вида \"ящик с усами\", который отражает среднее время обучения алгоритма при фиксированном значении гиперпараметров. Что вы можете сказать о скорости работы алгоритмов? Почему наблюдаются такие результаты? Можно ли ускорить? Если да, то каким образом?"
      ],
      "metadata": {
        "id": "oRzLNbl1vnIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WHOdN2g41GJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Определение гиперпараметров для подбора\n"
      ],
      "metadata": {
        "id": "t4BaVoO81IAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "param_grid_dt = {\n",
        "    'max_depth': range(1, 21),\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}"
      ],
      "metadata": {
        "id": "QZH-77A-NJ6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подбор оптимальных значений гиперпараметров для DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "4Dl4U1lk1Jmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_grid_search = GridSearchCV(dt_classifier, param_grid_dt, cv=5, scoring='accuracy')\n",
        "dt_grid_search.fit(train_data_processed, target)"
      ],
      "metadata": {
        "id": "IoHs9z2B1LR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод наилучших значений гиперпараметров и соответствующего качества\n"
      ],
      "metadata": {
        "id": "M9scDWhv1N7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DecisionTreeClassifier:\")\n",
        "print(\"Best Parameters:\", dt_grid_search.best_params_)\n",
        "print(\"Best CV Score:\", dt_grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "KQCywifR1NfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Измерение времени обучения DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "4rr-zHc91P_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def measure_training_time(classifier, train_data, target):\n",
        "    start_time = time.time()\n",
        "    classifier.fit(train_data, target)\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return training_time\n",
        "dt_classifier_best = DecisionTreeClassifier(**dt_grid_search.best_params_, random_state=42)\n",
        "dt_training_times = []\n",
        "for i in range(10):\n",
        "    dt_training_time = measure_training_time(dt_classifier_best, train_data_processed, target)\n",
        "    dt_training_times.append(dt_training_time)\n",
        "    print(f\"Iteration {i+1}: Training time = {dt_training_time:.4f} seconds\")\n",
        "print(\"Mean Training Time:\", np.mean(dt_training_times))\n",
        "print(\"Training Time Std:\", np.std(dt_training_times))"
      ],
      "metadata": {
        "id": "sNg9Eodo1P2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравнение результатов\n",
        "\n",
        "Сравните результаты алгоритмво. Для этого воспользуйтесь \"ящиком с усами\" (boxplot).\n",
        "\n",
        "Сделайте общие итоговые выводы о классификаторах с точки зрения их работы с признаками и сложности самой модели (какие гиперпараметры есть у модели, сильно ли изменение значения гиперпараметра влияет на качество модели)."
      ],
      "metadata": {
        "id": "V6SPsE847Ejl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение RandomForestClassifier с оптимальным числом деревьев\n"
      ],
      "metadata": {
        "id": "YQvFDpt91hpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "rf_classifier_optimal = RandomForestClassifier(n_estimators=stable_estimators, random_state=42)\n",
        "rf_training_times = []\n",
        "for i in range(10):\n",
        "    rf_training_time = measure_training_time(rf_classifier_optimal, train_data_processed, target)\n",
        "    rf_training_times.append(rf_training_time)\n",
        "    print(f\"Iteration {i+1}: Training time = {rf_training_time:.4f} seconds\")"
      ],
      "metadata": {
        "id": "0lxeK9x4qzbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод среднего времени обучения и доверительного интервала для RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "qS6Kpjvl1jNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RandomForestClassifier:\")\n",
        "print(\"Mean Training Time:\", np.mean(rf_training_times))\n",
        "print(\"Training Time Std:\", np.std(rf_training_times))\n"
      ],
      "metadata": {
        "id": "PECZSO721i8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сравнение времени обучения обеих моделей с помощью ящика с усами\n"
      ],
      "metadata": {
        "id": "XUDf_CVq1m5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=[dt_training_times, rf_training_times], palette=\"Set3\")\n",
        "plt.xticks([0, 1], ['DecisionTree', 'RandomForest'])\n",
        "plt.ylabel('Training Time (seconds)')\n",
        "plt.title('Comparison of Training Time between DecisionTree and RandomForest')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jvm3I5-a1lhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование всех модели\n",
        "\n",
        "Протестируйте последние построенные модели (наилучшее решающее дерево и наилучший случайный лес) на данных, которые были отложены для теста (их должно было остаться 40%). Не забудьте про все необходимые преобразования."
      ],
      "metadata": {
        "id": "zUwFUddE9hGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка тестовых данных\n"
      ],
      "metadata": {
        "id": "l6IJZkfI2pEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Загрузка исходных данных для определения категориальных признаков\n",
        "data = pd.read_csv(\"data.adult.csv\")\n",
        "\n",
        "# Определение категориальных признаков (например, если вы знаете, что определенные столбцы категориальные)\n",
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "\n",
        "# Выделение целевой переменной и преобразование к бинарному формату\n",
        "target = data['>50K,<=50K'].map({'<=50K': 0, '>50K': 1})\n",
        "data.drop(columns=['>50K,<=50K'], inplace=True)\n",
        "\n",
        "# Разделение на тренировочные и тестовые данные (60% на обучение, 40% на тест)\n",
        "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.4, random_state=42)\n",
        "\n",
        "# Сохранение тестовых данных в файл\n",
        "test_data['>50K,<=50K'] = test_target  # Восстановление целевой переменной в данных для теста\n",
        "test_data.to_csv(\"test_data.csv\", index=False)\n",
        "\n",
        "# Проверка наличия категориальных признаков в данных\n",
        "print(\"Категориальные признаки:\", categorical_features)\n",
        "print(\"Все столбцы в данных:\", data.columns.tolist())\n"
      ],
      "metadata": {
        "id": "UcVWWNCAsHbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle\n",
        "\n",
        "# Загрузка исходных данных\n",
        "data = pd.read_csv(\"test_data.csv\")\n",
        "\n",
        "# Удаление объектов с пропусками\n",
        "data = data.replace('?', pd.NA).dropna()\n",
        "\n",
        "# Выделение целевой переменной и преобразование к бинарному формату\n",
        "target = data['>50K,<=50K'].map({'<=50K': 0, '>50K': 1})\n",
        "data.drop(columns=['>50K,<=50K'], inplace=True)\n",
        "\n",
        "# Проверка наличия данных после удаления строк с отсутствующими значениями\n",
        "if not data.empty:\n",
        "    # Определение категориальных признаков\n",
        "    categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
        "\n",
        "    # Разделение на тренировочные и тестовые данные (60% на обучение, 40% на тест)\n",
        "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.4, random_state=42)\n",
        "\n",
        "    # Преобразование категориальных признаков с помощью One-Hot Encoding\n",
        "    train_data_categorical = pd.get_dummies(train_data[categorical_features])\n",
        "    train_data_processed = pd.concat([train_data.drop(columns=categorical_features), train_data_categorical], axis=1)\n",
        "\n",
        "    # Проверка на наличие отсутствующих значений в train_target\n",
        "    missing_indices = train_target[train_target.isnull()].index\n",
        "    if not missing_indices.empty:\n",
        "        train_data_processed = train_data_processed.drop(index=missing_indices)\n",
        "        train_target = train_target.drop(index=missing_indices)\n",
        "\n",
        "    # Проверка на наличие данных в train_data_processed\n",
        "    if not train_data_processed.empty and not train_target.empty:\n",
        "        # Сохранение списка признаков\n",
        "        train_features = train_data_processed.columns\n",
        "        with open('train_features.pkl', 'wb') as f:\n",
        "            pickle.dump(train_features, f)\n",
        "\n",
        "        # Обучение моделей\n",
        "        dt_classifier_best = DecisionTreeClassifier(random_state=42)\n",
        "        rf_classifier_best = RandomForestClassifier(random_state=42)\n",
        "\n",
        "        dt_classifier_best.fit(train_data_processed, train_target)\n",
        "        rf_classifier_best.fit(train_data_processed, train_target)\n",
        "        # Сохранение моделей\n",
        "        with open('dt_classifier_best.pkl', 'wb') as f:\n",
        "            pickle.dump(dt_classifier_best, f)\n",
        "\n",
        "        with open('rf_classifier_best.pkl', 'wb') as f:\n",
        "            pickle.dump(rf_classifier_best, f)\n",
        "\n",
        "        # Сохранение тестовых данных в файл\n",
        "        test_data['>50K,<=50K'] = test_target\n",
        "        # Восстановление целевой переменной в данных для теста\n",
        "        test_data.to_csv(\"test_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "aClWETCs9wgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Удаление объектов с пропусками\n"
      ],
      "metadata": {
        "id": "QDDbXmE63JoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data.replace('?', pd.NA).dropna()\n"
      ],
      "metadata": {
        "id": "iNYBxYIo_NqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выделение целевой переменной и преобразование к бинарному формату\n"
      ],
      "metadata": {
        "id": "cX6iyUcn3I1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(\"test_data.csv\")\n",
        "test_target = test_data['>50K,<=50K'].map({'<=50K': 0, '>50K': 1})\n",
        "test_data.drop(columns=['>50K,<=50K'], inplace=True)"
      ],
      "metadata": {
        "id": "q56WxQpw3Ox_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Преобразование категориальных признаков с помощью One-Hot Encoding\n"
      ],
      "metadata": {
        "id": "owEBZSyo3QB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_categorical = pd.get_dummies(test_data[categorical_features])\n"
      ],
      "metadata": {
        "id": "0EDUwPnB3QoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Добавление закодированных категориальных признаков к вещественным данным\n"
      ],
      "metadata": {
        "id": "CFO1xqcI3SnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_processed = pd.concat([test_data.drop(columns=categorical_features), test_data_categorical], axis=1)\n"
      ],
      "metadata": {
        "id": "mxKJvkIc3TWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Оценка качества модели на тестовой выборке\n"
      ],
      "metadata": {
        "id": "QC9FeumH3VVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование категориальных признаков тестовых данных с помощью One-Hot Encoding\n",
        "test_data_categorical = pd.get_dummies(test_data[categorical_features])\n",
        "test_data_processed = pd.concat([test_data.drop(columns=categorical_features), test_data_categorical], axis=1)\n"
      ],
      "metadata": {
        "id": "JoHt2rONxYKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.columns)"
      ],
      "metadata": {
        "id": "VfwKCMcrygcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "data_path = '/content/data.adult.csv'\n",
        "test_data_path = '/content/test_data.csv'\n",
        "\n",
        "data = pd.read_csv(data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Создание искусственной целевой переменной на основе 'hours-per-week'\n",
        "# Например, пусть целевая переменная будет 1, если человек работает более 40 часов в неделю, иначе 0\n",
        "data['target'] = (data['hours-per-week'] > 40).astype(int)\n",
        "test_data['target'] = (test_data['hours-per-week'] > 40).astype(int)\n",
        "\n",
        "# Выделение целевой переменной и признаков\n",
        "target = 'target'\n",
        "features = data.columns.drop(target)\n",
        "\n",
        "X_train = data[features]\n",
        "y_train = data[target]\n",
        "\n",
        "X_test = test_data[features]\n",
        "y_test = test_data[target]\n",
        "\n",
        "# Преобразование категориальных признаков с помощью One-Hot Encoding\n",
        "X_train = pd.get_dummies(X_train)\n",
        "X_test = pd.get_dummies(X_test)\n",
        "\n",
        "# Убедимся, что все столбцы совпадают в тренировочных и тестовых данных\n",
        "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Обучение и оценка моделей\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "rf_classifier = RandomForestClassifier()\n",
        "\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "dt_test_score = dt_classifier.score(X_test, y_test)\n",
        "rf_test_score = rf_classifier.score(X_test, y_test)\n",
        "\n",
        "# Вывод результатов\n",
        "print(\"DecisionTreeClassifier Test Score:\", dt_test_score)\n",
        "print(\"RandomForestClassifier Test Score:\", rf_test_score)\n"
      ],
      "metadata": {
        "id": "N5-Whc8Ie50j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод результатов"
      ],
      "metadata": {
        "id": "ZPbhfoZy3YTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод результатов\n",
        "print(\"DecisionTreeClassifier Test Score:\", dt_test_score)\n",
        "print(\"RandomForestClassifier Test Score:\", rf_test_score)\n"
      ],
      "metadata": {
        "id": "g4ABHG933ZbK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-rX8cvHCzany"
      ],
      "private_outputs": true,
      "cell_execution_strategy": "setup"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}